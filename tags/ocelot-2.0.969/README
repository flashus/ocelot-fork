Take a look at http://code.google.com/p/gpuocelot/ for detailed installation info

To Install Ocelot:
	./configure; sudo make install

To Link Against Ocelot:
	g++ program.cu.cpp `OcelotConfig -l`

To Run Ocelot:
	Run your CUDA program normally with a 'configure.ocelot' file 
		in the same directory (see the website for samples)

Ocelot Version 2.0.969 Features:
 1) Four target devices
	 a) PTX 2.1 Emulator 
	 	i)   Memory Checker
	 		  -out of bounds accesses
	 		  -misalgined accesses
	 	ii)  Shared Memory Race Detector
	 	iii) Interactive PTX Debugger
	 b) PTX 2.1 JIT Compiler and CPU Runtime
	 	i)   Execute CUDA programs natively on CPU targets without emulation
	 	ii)  Support for any LLVM target
	 	iii) Requires LLVM 2.9
	 	iv)  Can achieve over 80% of theoretical peak FLOPs/OPs on CPU targets
	 c) NVIDIA GPU JIT
	 	i) Recompiles PTX kernels using the NVIDIA Driver
	 d) AMD GPU JIT
	    i)   Translates PTX to CAL (IL)
	    ii)  Executes compiled kernels using the AMD Driver
	    iii) Beta release, there are still some bugs here
 2) Reimplementation of the CUDA Runtime
 	a) Device Switching
 		- The same host thread can simultaneously control multiple devices.
 	b) New Memory Model
 		- Device allocations are shared among all host threads
 3) PTXOptimizer
 	a) Extendible optimization pass interface for PTX
 		- Per-Block, Per-Kernel, Per-Module passes 
 4) Trace Generators
 	a) Extendible interface for instrumenting PTX kernels
 	b) Can examine the complete system state after each instruction is executed
 		i) Registers
 		ii) Memory Accesses
 		iii) Last instruction executed
 		iv) Thread activity mask

Open Projects for Ocelot 2.1
 1) Language frontends (OpenCL)
 2) Additional PTX to PTX optimization passes
 3) Remote devices
 4) Cuda kernel trace capture/replay
 5) Additional GPU backends (Research architectures, Intel GEN)
 6) Vanaheimr (reimplement all of Ocelot in CUDA)
 7) Develop a binary format for PTX
